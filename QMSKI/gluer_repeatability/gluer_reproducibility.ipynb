{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate coefficient of variation as per Gl端er et al. (1995)\n",
    "\n",
    "Author: Simone Poncioni, MSB, ARTORG Center for Biomedical Engineering Research, University of Bern, Switzerland\n",
    "\n",
    "Date: 07.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cv_gluer(infile: pd.DataFrame, outfile: dict, variable: str):\n",
    "    \"\"\"Function to calculate the coefficient of variation as per Gl端er et al. 1995\n",
    "\n",
    "    Args:\n",
    "        infile (pd.DataFrame): DataFrame containing the imported yaml file with the simulation grouping information\n",
    "        outfile (dict): simulation results file\n",
    "        variable (str): variable to analyse (e.g. 'Stiffness', 'yield_force', etc.)\n",
    "    \"\"\"\n",
    "    def dofs(results):\n",
    "        '''\n",
    "        Equation (7), calculating the degrees of fredom df_j of the measurements in the individuals\n",
    "        '''\n",
    "        counter = Counter()\n",
    "        for value in results.values():\n",
    "            key_part = value[0].split('/')[1]\n",
    "            counter[key_part] += 1\n",
    "        degrees_of_freedom = sum(count - 1 for count in counter.values())\n",
    "        return degrees_of_freedom\n",
    "\n",
    "    def precision_error(results):\n",
    "        '''\n",
    "        Equation (6), calculating the generic standard deviation sd of the measurements\n",
    "        '''\n",
    "        values_sorted = defaultdict(list)\n",
    "        for _, value in results.items():\n",
    "            key_part = value[0].split('/')[1]\n",
    "            values_sorted[key_part].append(value[1])\n",
    "        \n",
    "        sum_tot = 0\n",
    "        total_elements = 0\n",
    "        df = 0\n",
    "\n",
    "        # Calculating the internal mean, sum of squared differences, and degrees of freedom\n",
    "        for key, values in values_sorted.items():\n",
    "            internal_mean = sum(values) / len(values)\n",
    "            total_elements += len(values)\n",
    "            df += len(values) - 1  # Adding to degrees of freedom\n",
    "            \n",
    "            for xij in values:\n",
    "                sum_tot += (xij - internal_mean) ** 2\n",
    "\n",
    "        # Dividing by degrees of freedom\n",
    "        variance = sum_tot / df\n",
    "        sd = variance ** 0.5\n",
    "\n",
    "        return sd, values_sorted\n",
    "\n",
    "    def coefficient_of_variation(sd, values_sorted):\n",
    "        '''\n",
    "        Equation (5), calculating the coefficient of variation on a percentage basis\n",
    "        '''\n",
    "        HUNDRED = 100\n",
    "        sum_means = 0\n",
    "        m = len(values_sorted)\n",
    "\n",
    "        for _, values in values_sorted.items():\n",
    "            internal_mean = sum(values) / len(values)\n",
    "            sum_means += internal_mean\n",
    "        \n",
    "        mean_of_means = sum_means / m\n",
    "        cv_sd = (sd / mean_of_means) * HUNDRED\n",
    "        return cv_sd\n",
    "\n",
    "    out_samples = outfile['Sample'].values\n",
    "    out_samples = [str(sample) for sample in out_samples]\n",
    "    results_dict = {}\n",
    "    for sample in out_samples:\n",
    "        variable_res = outfile[outfile['Sample'] == sample][str(variable)]\n",
    "        # add key 'variable' to results_dict (which has sample as key, infile['simulations']['folder_id'][sample] as value 0, and 'variable' as value 1)\n",
    "        results_dict[sample] = [infile['simulations']['folder_id'][sample], variable_res.values[0]]\n",
    "\n",
    "    # split results_dict into two dictionaries: results_r and results_t\n",
    "    # ->>> results_r contains infile['simulations']['folder_id'][sample][-1] == 'R'\n",
    "    # ->>> results_t contains infile['simulations']['folder_id'][sample][-1] == 'T'\n",
    "\n",
    "    results_r = {}\n",
    "    results_t = {}\n",
    "    for key, value in results_dict.items():\n",
    "        if value[0][-1] == 'R':\n",
    "            results_r[key] = value\n",
    "        elif value[0][-1] == 'T':\n",
    "            results_t[key] = value\n",
    "            \n",
    "    property_r = [value[1] for value in results_r.values()]\n",
    "    property_t = [value[1] for value in results_t.values()]\n",
    "\n",
    "    property = [property_r, property_t]\n",
    "    results = [results_r, results_t]\n",
    "    site = ['RADIUS', 'TIBIA']\n",
    "\n",
    "    df1 = pd.DataFrame()\n",
    "    # as per Gl端er et al. 1995\n",
    "    for res, stiff, _site in zip(results, property, site):\n",
    "        m = len(stiff)\n",
    "        df = dofs(res)\n",
    "        sd, values_sorted = precision_error(res)\n",
    "        cv_sd = coefficient_of_variation(sd, values_sorted)\n",
    "        # append to df\n",
    "        df_temp = pd.DataFrame({'Variable': variable, 'm': m, 'df': df, 'sd': sd, 'cv_sd': cv_sd}, index=[_site])\n",
    "        df1 = pd.concat([df1, df_temp])\n",
    "\n",
    "    df1.index.name = 'Site'\n",
    "    df1.reset_index(inplace=True)\n",
    "    df1.set_index(['Site', 'Variable'], inplace=True)\n",
    "    df1.reset_index(inplace=True)  # Reset index to make 'Site' and 'Variable' regular columns\n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "def pivot_dataframe(df: pd.DataFrame):\n",
    "    df_res_pivot = df.pivot(index='Variable', columns='Site')\n",
    "    df_res_pivot.columns = ['_'.join(col).strip() for col in df_res_pivot.columns.values]\n",
    "    new_column_order = ['m_RADIUS', 'df_RADIUS', 'sd_RADIUS', 'cv_sd_RADIUS', 'm_TIBIA', 'df_TIBIA', 'sd_TIBIA', 'cv_sd_TIBIA']\n",
    "    df_res_pivot = df_res_pivot[new_column_order]\n",
    "    return df_res_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results\n",
    "in_path = Path('summaries/simulations-repro.yaml')\n",
    "with open(in_path, 'r') as f:\n",
    "    infile = yaml.safe_load(f)\n",
    "\n",
    "# * Indermaur et al. (in preparation, 2024)\n",
    "# outfile_path = Path('summaries/REPRO_mech_param_FEA_noReg__V_00_noReg_FZ_MAX_sphere_changed.csv')\n",
    "# variables_to_analyse = ['Stiffness', 'yield_force']\n",
    "\n",
    "# * Ours (Poncioni et al., in preparation, 2024)\n",
    "outfile_path = Path('summaries/06_repro_paper_data_summary.csv')\n",
    "# variables_to_analyse = ['stiffness_1D_FZ_MAX', 'yield_force_FZ_MAX', 'yield_disp_FZ_MAX', 'max_force_FZ_MAX', 'disp_at_max_force_FZ_MAX', 'Volume', 'tb_bv', 'ct_bv']\n",
    "variables_to_analyse = ['stiffness_1D_FZ_MAX', 'yield_force_FZ_MAX']\n",
    "outfile = pd.read_csv(outfile_path, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results as per Gl端er et al. 1995\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "for var in variables_to_analyse:\n",
    "    df_res = calculate_cv_gluer(infile, outfile, var)\n",
    "    df_res_pivot = pivot_dataframe(df_res)\n",
    "    df_results = pd.concat([df_results, df_res_pivot])\n",
    "\n",
    "print(df_results.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the results\n",
    "in_path = Path('summaries/simulations-repro.yaml')\n",
    "with open(in_path, 'r') as f:\n",
    "    infile = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "outfiles = [Path('summaries/REPRO_mech_param_FEA_noReg__V_00_noReg_FZ_MAX_sphere_changed.csv'), Path('summaries/03_repro_vtu_data_summary_with_volumes.csv')]\n",
    "variables_to_analyse_list = [['Stiffness', 'yield_force', 'yield_disp', 'max_force', 'disp_max_force'], ['stiffness_1D_FZ_MAX', 'yield_force_FZ_MAX', 'yield_disp_FZ_MAX', 'max_force_FZ_MAX', 'disp_at_max_force_FZ_MAX']]\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "for outfile, variables_to_analyse in zip(outfiles, variables_to_analyse_list):\n",
    "    \n",
    "    outfile_df = pd.read_csv(outfile, delimiter=',')\n",
    "    for var in variables_to_analyse:\n",
    "        df_res = calculate_cv_gluer(infile, outfile_df, var)\n",
    "        # Pivot the DataFrame\n",
    "        df_res_pivot = pivot_dataframe(df_res)\n",
    "        \n",
    "        df_results = pd.concat([df_results, df_res_pivot])\n",
    "    print(df_results.to_string())\n",
    "    if outfile == outfiles[0]:\n",
    "        df1 = df_results.copy()\n",
    "    else:\n",
    "        df2 = df_results.copy()\n",
    "\n",
    "# df_tot = pd.concat([df1, df2], axis=0)\n",
    "df_tot = df2\n",
    "# Assuming df1 and df2 are already loaded\n",
    "\n",
    "# Normalize column names for comparison\n",
    "# Map df1 columns to df2 columns based on the order specified in the question\n",
    "columns_mapping = {\n",
    "    'Stiffness': 'stiffness_1D_FZ_MAX',\n",
    "    'yield_force': 'yield_force_FZ_MAX',\n",
    "    'yield_disp': 'yield_disp_FZ_MAX',\n",
    "    'max_force': 'max_force_FZ_MAX',\n",
    "    'disp_max_force': 'disp_at_max_force_FZ_MAX'\n",
    "}\n",
    "\n",
    "# Prepare comparison data\n",
    "comparison_data = {\n",
    "    'Variable': [],\n",
    "    'cv_sd_RADIUS_df1': [],\n",
    "    'cv_sd_TIBIA_df1': [],\n",
    "    'cv_sd_RADIUS_df2': [],\n",
    "    'cv_sd_TIBIA_df2': []\n",
    "}\n",
    "\n",
    "print(f'Complete data:\\n\\n{df_tot.to_string()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('/home/simoneponcioni/Documents/00_GENERAL/pos_monitor.mplstyle')\n",
    "\n",
    "# get index of the dataframe\n",
    "index = df_tot.index\n",
    "\n",
    "# Mapping of properties\n",
    "columns_mapping = {\n",
    "    'Stiffness': 'stiffness_1D_FZ_MAX',\n",
    "    'yield_force': 'yield_force_FZ_MAX',\n",
    "    'yield_disp': 'yield_disp_FZ_MAX',\n",
    "    'max_force': 'max_force_FZ_MAX',\n",
    "    'disp_max_force': 'disp_at_max_force_FZ_MAX'\n",
    "}\n",
    "\n",
    "# Create a new DataFrame with both original and mapped values\n",
    "properties = list(columns_mapping.keys())\n",
    "mapped_properties = list(columns_mapping.values())\n",
    "\n",
    "# Extract cv_sd_RADIUS values\n",
    "original_values = df_tot.loc[properties, 'cv_sd_RADIUS']\n",
    "mapped_values = df_tot.loc[mapped_properties, 'cv_sd_RADIUS']\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "plot_data = pd.DataFrame({\n",
    "    'Property': properties + mapped_properties,\n",
    "    'cv_sd_RADIUS': list(original_values) + list(mapped_values)\n",
    "})\n",
    "\n",
    "# Create a new DataFrame with both original and mapped values\n",
    "plot_data = []\n",
    "for orig, mapped in columns_mapping.items():\n",
    "    plot_data.append({\n",
    "        'Property': orig,\n",
    "        'cv_sd_RADIUS': abs(df_tot.loc[orig, 'cv_sd_RADIUS']),\n",
    "        'Type': 'Original'\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'Property': mapped,\n",
    "        'cv_sd_RADIUS': abs(df_tot.loc[mapped, 'cv_sd_RADIUS']),\n",
    "        'Type': 'Mapped'\n",
    "    })\n",
    "\n",
    "plot_data = pd.DataFrame(plot_data)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "bar_width = 0.5\n",
    "indices = np.arange(len(columns_mapping))\n",
    "positions = np.array([2 * i for i in range(len(columns_mapping))])\n",
    "\n",
    "original_bars = plt.bar(positions, plot_data[plot_data['Type'] == 'Original']['cv_sd_RADIUS'], bar_width, label='Indermaur et al. (2021)')\n",
    "spline_bars = plt.bar(positions + bar_width, plot_data[plot_data['Type'] == 'Mapped']['cv_sd_RADIUS'], bar_width, label='Ours')\n",
    "\n",
    "# Add labels\n",
    "plt.ylabel('$CV_{SD}$ Radius')\n",
    "plt.title('Comparison of CV - Radius', weight='bold')\n",
    "middle_positions = positions + bar_width // 2\n",
    "plt.xticks(ticks=middle_positions, labels=columns_mapping.keys(), rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of the dataframe\n",
    "index = df_tot.index\n",
    "\n",
    "# Mapping of properties\n",
    "columns_mapping = {\n",
    "    'Stiffness': 'stiffness_1D_FZ_MAX',\n",
    "    'yield_force': 'yield_force_FZ_MAX',\n",
    "    'yield_disp': 'yield_disp_FZ_MAX',\n",
    "    'max_force': 'max_force_FZ_MAX',\n",
    "    'disp_max_force': 'disp_at_max_force_FZ_MAX'\n",
    "}\n",
    "\n",
    "# Create a new DataFrame with both original and mapped values\n",
    "properties = list(columns_mapping.keys())\n",
    "mapped_properties = list(columns_mapping.values())\n",
    "\n",
    "# Extract cv_sd_TIBIA values\n",
    "original_values = df_tot.loc[properties, 'cv_sd_TIBIA']\n",
    "mapped_values = df_tot.loc[mapped_properties, 'cv_sd_TIBIA']\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "plot_data = pd.DataFrame({\n",
    "    'Property': properties + mapped_properties,\n",
    "    'cv_sd_TIBIA': list(original_values) + list(mapped_values)\n",
    "})\n",
    "\n",
    "# Create a new DataFrame with both original and mapped values\n",
    "plot_data = []\n",
    "for orig, mapped in columns_mapping.items():\n",
    "    plot_data.append({\n",
    "        'Property': orig,\n",
    "        'cv_sd_TIBIA': abs(df_tot.loc[orig, 'cv_sd_TIBIA']),\n",
    "        'Type': 'Original'\n",
    "    })\n",
    "    plot_data.append({\n",
    "        'Property': mapped,\n",
    "        'cv_sd_TIBIA': abs(df_tot.loc[mapped, 'cv_sd_TIBIA']),\n",
    "        'Type': 'Mapped'\n",
    "    })\n",
    "\n",
    "plot_data = pd.DataFrame(plot_data)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "bar_width = 0.5\n",
    "indices = np.arange(len(columns_mapping))\n",
    "positions = np.array([2 * i for i in range(len(columns_mapping))])\n",
    "\n",
    "original_bars = plt.bar(positions, plot_data[plot_data['Type'] == 'Original']['cv_sd_TIBIA'], bar_width, label='Indermaur et al. (2021)')\n",
    "spline_bars = plt.bar(positions + bar_width, plot_data[plot_data['Type'] == 'Mapped']['cv_sd_TIBIA'], bar_width, label='Ours')\n",
    "\n",
    "# Add labels\n",
    "plt.ylabel('$CV_{SD}$ Tibia')\n",
    "plt.title('Comparison of CV - Tibia', weight='bold')\n",
    "middle_positions = positions + bar_width // 2\n",
    "plt.xticks(ticks=middle_positions, labels=columns_mapping.keys(), rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
