{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyssam\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista as pv\n",
    "import point_cloud_utils as pcu\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = Path('/home/simoneponcioni/Documents/01_PHD/03_Methods/HFE/01_DATA/TIBIA')\n",
    "landmarkpath = Path('/home/simoneponcioni/Documents/01_PHD/03_Methods/HFE/QMSKI/SSAM/') / 'landmarks_ext'\n",
    "landmarkpath = Path('/home/simoneponcioni/Documents/01_PHD/03_Methods/HFE/QMSKI/SSAM/') / 'landmarks_int'\n",
    "# for all subdirs, get all '_CORTMASK' files\n",
    "cort_list = []\n",
    "trab_list = []\n",
    "for file in basepath.iterdir():\n",
    "    if file.is_file() and '_CORTMASK' in file.name and 'mhd' in file.suffix:\n",
    "        trab_list.append(file)\n",
    "\n",
    "# for all subdirs, get all '_TRABMASK' files\n",
    "trab_list = []\n",
    "for file in basepath.iterdir():\n",
    "    if file.is_file() and '_TRABMASK' in file.name and 'mhd' in file.suffix:\n",
    "        trab_list.append(file)\n",
    "\n",
    "# # for each file, create a numpy array and save it as a .npy file in a temp dir\n",
    "# landmark_files = []\n",
    "# for file in cort_list:\n",
    "#     sitk_image = sitk.ReadImage(str(file))\n",
    "#     np_image = sitk.GetArrayFromImage(sitk_image)\n",
    "#     landmark_files.append(landmarkpath / file.with_suffix('.npy').name)\n",
    "#     np.save(landmarkpath / file.with_suffix('.npy').name, np_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_voxels_per_axis = 4096\n",
    "num_landmarks = 1024\n",
    "\n",
    "landmarks_list = []\n",
    "for file in trab_list:\n",
    "    print(file)\n",
    "    img = pv.read(str(file))\n",
    "    point_items = img.point_data.items()\n",
    "    print(point_items)\n",
    "    pv_threshold = img.threshold(value=1,\n",
    "                                 scalars='MetaImage')\n",
    "\n",
    "    surf = pv.DataSetFilters.extract_surface(pv_threshold)\n",
    "    points = surf.points\n",
    "    print(len(points))\n",
    "    normals = np.array(surf.point_normals, dtype=np.float32)\n",
    "    values = np.ones(np.shape(points)[0], dtype=np.float32)\n",
    "    # values = np.array(surf.point_data['vtkOriginalPointIds'], dtype=np.float32)\n",
    "    plt.figure()\n",
    "    plt.scatter(points[:, 0], points[:, 1], s=1)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "#     points = np.array(points, dtype=np.float32)\n",
    "#     v, n, c = points, normals, values\n",
    "\n",
    "#     # Size of the axis aligned bounding box of the point cloud\n",
    "#     bbox_size = v.max(0) - v.min(0)\n",
    "\n",
    "#     # The size per-axis of a single voxel\n",
    "#     sizeof_voxel = bbox_size / num_voxels_per_axis\n",
    "\n",
    "#     # Downsample a point cloud on a voxel grid so there is at most one point per voxel.\n",
    "#     # Any arguments after the points are treated as attribute arrays and get averaged within each voxel\n",
    "#     v_sampled, n_sampled, c_sampled = pcu.downsample_point_cloud_on_voxel_grid(sizeof_voxel, v, n, c)\n",
    "\n",
    "#     # Ensure the sampled points have the shape (num_landmarks, 3)\n",
    "#     if v_sampled.shape[0] > num_landmarks:\n",
    "#         indices = np.random.choice(v_sampled.shape[0], num_landmarks, replace=False)\n",
    "#         v_sampled = v_sampled[indices]\n",
    "#     elif v_sampled.shape[0] < num_landmarks:\n",
    "#         padding = np.zeros((num_landmarks - v_sampled.shape[0], 3), dtype=np.float32)\n",
    "#         v_sampled = np.vstack((v_sampled, padding))\n",
    "\n",
    "#     landmarks_list.append(v_sampled)\n",
    "\n",
    "# landmark_coordinates = np.array(landmarks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm_obj = pyssam.SSM(landmark_coordinates)\n",
    "ssm_obj.create_pca_model(ssm_obj.landmarks_columns_scale)\n",
    "mean_shape_columnvector = ssm_obj.compute_dataset_mean()\n",
    "mean_shape = mean_shape_columnvector.reshape(-1, 3)\n",
    "shape_model_components = ssm_obj.pca_model_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some plotting functions\n",
    "\n",
    "def plot_cumulative_variance(explained_variance, target_variance=-1):\n",
    "    number_of_components = np.arange(0, len(explained_variance))+1\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    color = \"blue\"\n",
    "    ax.plot(number_of_components, explained_variance*100.0, marker=\"o\", ms=2, color=color, mec=color, mfc=color)\n",
    "    if target_variance > 0.0:\n",
    "        ax.axhline(target_variance*100.0)\n",
    "    \n",
    "    ax.set_ylabel(\"Variance [%]\")\n",
    "    ax.set_xlabel(\"Number of components\")\n",
    "    ax.grid(axis=\"x\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_shape_modes(\n",
    "  mean_shape_columnvector, \n",
    "  mean_shape, \n",
    "  original_shape_parameter_vector,\n",
    "  shape_model_components,\n",
    "  mode_to_plot,\n",
    "):\n",
    "  weights = [-2, 0, 2]\n",
    "  fig, ax = plt.subplots(1, 3)\n",
    "  for j, weights_i in enumerate(weights):\n",
    "    shape_parameter_vector = copy(original_shape_parameter_vector)\n",
    "    shape_parameter_vector[mode_to_plot] = weights_i\n",
    "    mode_i_coords = ssm_obj.morph_model(\n",
    "        mean_shape_columnvector, \n",
    "        shape_model_components, \n",
    "        shape_parameter_vector\n",
    "    ).reshape(-1, 3)\n",
    "\n",
    "    offset_dist = pyssam.utils.euclidean_distance(\n",
    "      mean_shape, \n",
    "      mode_i_coords\n",
    "    )\n",
    "    # colour points blue if closer to point cloud centre than mean shape\n",
    "    mean_shape_dist_from_centre = pyssam.utils.euclidean_distance(\n",
    "      mean_shape,\n",
    "      np.zeros(3),\n",
    "    )\n",
    "    mode_i_dist_from_centre = pyssam.utils.euclidean_distance(\n",
    "      mode_i_coords,\n",
    "      np.zeros(3),\n",
    "    )\n",
    "    offset_dist = np.where(\n",
    "        mode_i_dist_from_centre<mean_shape_dist_from_centre,\n",
    "        offset_dist*-1,\n",
    "        offset_dist,\n",
    "    )\n",
    "    if weights_i == 0:\n",
    "      ax[j].scatter(\n",
    "        mode_i_coords[:, 0],\n",
    "        mode_i_coords[:, 2],\n",
    "        c=\"gray\",\n",
    "        s=1,\n",
    "      )\n",
    "      ax[j].set_title(\"mean shape\")\n",
    "    else:\n",
    "      ax[j].scatter(\n",
    "        mode_i_coords[:, 0],\n",
    "        mode_i_coords[:, 2],\n",
    "        c=offset_dist,\n",
    "        cmap=\"seismic\",\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        s=1,\n",
    "      )\n",
    "      ax[j].set_title(f\"mode {mode_to_plot} \\nweight {weights_i}\")\n",
    "    ax[j].axis('off')\n",
    "    ax[j].margins(0,0)\n",
    "    ax[j].xaxis.set_major_locator(plt.NullLocator())\n",
    "    ax[j].yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"To obtain {ssm_obj.desired_variance*100}% variance, {ssm_obj.required_mode_number} modes are required\")\n",
    "plot_cumulative_variance(np.cumsum(ssm_obj.pca_object.explained_variance_ratio_), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_to_plot = 1\n",
    "print(f\"explained variance is {ssm_obj.pca_object.explained_variance_ratio_[mode_to_plot]}\")\n",
    "\n",
    "plot_shape_modes(\n",
    "    mean_shape_columnvector, \n",
    "    mean_shape, \n",
    "    ssm_obj.model_parameters,\n",
    "    ssm_obj.pca_model_components,\n",
    "    mode_to_plot,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mean shape to pyvista mesh\n",
    "mean_shape_mesh = pv.PolyData(mean_shape)\n",
    "mean_shape_mesh.plot(notebook=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
